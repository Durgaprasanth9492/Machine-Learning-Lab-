{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1s7TlkxSah2z2gYwdemMvs7p6Z6VOMy7Q","timestamp":1756458552429}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#  Install dependencies\n","%pip install -q scikit-learn pandas\n","\n","import os\n","import re\n","import zipfile\n","import urllib.request\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import classification_report\n","\n","# === Step 1: Download and unzip dataset ===\n","url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/mix20_rand700_tokens_cleaned.zip\"\n","zip_path = \"mix20_rand700_tokens_cleaned.zip\"\n","data_folder = \"mix20_rand700_tokens_cleaned\"\n","\n","if not os.path.exists(zip_path):\n","    print(\" Downloading dataset...\")\n","    urllib.request.urlretrieve(url, zip_path)\n","\n","if not os.path.exists(data_folder):\n","    print(\" Unzipping dataset...\")\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(data_folder)\n","\n","# === Step 2: Load reviews and assign labels ===\n","texts, labels = [], []\n","\n","# Define the paths to the positive and negative directories within 'tokens'\n","pos_dir = os.path.join(data_folder, 'tokens', 'pos')\n","neg_dir = os.path.join(data_folder, 'tokens', 'neg')\n","\n","# Load positive reviews\n","if os.path.exists(pos_dir):\n","    for fname in os.listdir(pos_dir):\n","        if fname.endswith('.txt'): # Assuming the review files are .txt\n","            with open(os.path.join(pos_dir, fname), 'r', encoding='utf-8', errors='ignore') as f:\n","                texts.append(f.read())\n","                labels.append('pos')\n","else:\n","    print(f\"Warning: Positive reviews directory not found at {pos_dir}\")\n","\n","# Load negative reviews\n","if os.path.exists(neg_dir):\n","    for fname in os.listdir(neg_dir):\n","        if fname.endswith('.txt'): # Assuming the review files are .txt\n","            with open(os.path.join(neg_dir, fname), 'r', encoding='utf-8', errors='ignore') as f:\n","                texts.append(f.read())\n","                labels.append('neg')\n","else:\n","     print(f\"Warning: Negative reviews directory not found at {neg_dir}\")\n","\n","print(f\" Loaded {len(texts)} reviews.\")\n","\n","\n","# === Step 3: Train/test split ===\n","X_train, X_test, y_train, y_test = train_test_split(\n","    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",")\n","\n","# === Step 4: Define models ===\n","models = {\n","    \"Naive Bayes\": Pipeline([\n","        ('tfidf', TfidfVectorizer()),\n","        ('clf', MultinomialNB()),\n","    ]),\n","    \"Logistic Regression (MaxEnt)\": Pipeline([\n","        ('tfidf', TfidfVectorizer()),\n","        ('clf', LogisticRegression(max_iter=1000)),\n","    ]),\n","    \"Support Vector Machine\": Pipeline([\n","        ('tfidf', TfidfVectorizer()),\n","        ('clf', LinearSVC()),\n","    ])\n","}\n","\n","# === Step 5: Train and evaluate ===\n","for name, model in models.items():\n","    print(f\"\\n=====  {name} =====\")\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    print(classification_report(y_test, y_pred, target_names=[\"neg\", \"pos\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5a799cIc2w_","executionInfo":{"status":"ok","timestamp":1762670699412,"user_tz":-330,"elapsed":18487,"user":{"displayName":"durgaprasanth","userId":"08399602778327095816"}},"outputId":"0efb2af1-06b5-4504-d152-1110dc019690"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[" Loaded 1400 reviews.\n","\n","=====  Naive Bayes =====\n","              precision    recall  f1-score   support\n","\n","         neg       0.75      0.86      0.80       140\n","         pos       0.83      0.72      0.77       140\n","\n","    accuracy                           0.79       280\n","   macro avg       0.79      0.79      0.79       280\n","weighted avg       0.79      0.79      0.79       280\n","\n","\n","=====  Logistic Regression (MaxEnt) =====\n","              precision    recall  f1-score   support\n","\n","         neg       0.78      0.78      0.78       140\n","         pos       0.78      0.78      0.78       140\n","\n","    accuracy                           0.78       280\n","   macro avg       0.78      0.78      0.78       280\n","weighted avg       0.78      0.78      0.78       280\n","\n","\n","=====  Support Vector Machine =====\n","              precision    recall  f1-score   support\n","\n","         neg       0.81      0.77      0.79       140\n","         pos       0.78      0.82      0.80       140\n","\n","    accuracy                           0.80       280\n","   macro avg       0.80      0.80      0.80       280\n","weighted avg       0.80      0.80      0.80       280\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cr_0XxPNc8Aj","executionInfo":{"status":"ok","timestamp":1762670699434,"user_tz":-330,"elapsed":5,"user":{"displayName":"durgaprasanth","userId":"08399602778327095816"}}},"execution_count":2,"outputs":[]}]}